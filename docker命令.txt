Docker（是一个软件，可以做容器）（是宿主机的一个大进程）
	概念
		docker.io 官方网站
		docker.inc 公司的名字
		rd开发 op运维
		轻量级虚拟机 每个容器共享宿主机内核（秒级启动）
		传统虚拟机    每台虚拟机拥有一个独立的内核（分钟级启动）
	Docker 三大核心组件
		Docker镜像-Docker images
		Docker仓库-Docker registeries
			关系       仓库(registry)-->Repository(小仓库)-->镜像（按版本区分）
			       类比 yum库-->不同的repo-->软件(按名字区分)	
			公有库（给全世界所有人用）（docker在中国没有服务器，所以有时候很慢）
				doucker.io
			私有库（自用）
				docker国内仓库(阿里,网易蜂巢，daocloud）
		Docker容器-Docker containers（不完全正确说法，运行起来的镜像叫做容器）
			概念： 由多层文件系统组成，最上层的文件系统能看见下层文件系统的东西
				centos:7(父镜像)--run容器--安装nginx--打包成镜像(子镜像)--run容器 
	Docker安装
		yum -y install docker
		systemctl start docker;systemctl enable docker;
		docker version
		docker pull daocloud.io/centos:latest       国内库拉取镜像（想要查看有什么版本镜像https://hub.daocloud.io/  登陆）
		docker run -it ubuntu bash    (本地没有镜像会自动下载后运行，若前面没有加仓库名字会默认为官方库)
		docker search tomcat  -s 100 （可查看官方源中所要下载的所有版本 -s 为下载热度，国内源要登陆其网站才能查）
	Docker使用daocloud.io仓库加速器 （国内源速度快）
		vim /etc/docker/daemon.json
			{
			    "registry-mirrors": [
			        "http://f1361db2.m.daocloud.io"           加速地址要进入daocloud的官方网站注册获取，每个账号的地址都不一样
			    ],
			    "insecure-registries": []
			}
		systemctl restart docker （dao pull 拉取镜像）
		登陆官网后点击集群管理
		添加主机
		curl -sSL https://get.daocloud.io/daomonit/install.sh | sh -s d88263f6741e3d73448705346d69fbd4556caae9  （安装主机监控程序，每个账号都不一样）
	docker使用
		docker search tomcat  -s 100		搜索镜像
		docker pull centos			拉取镜像、		
		docker image list 			查看已拉取的镜像（或者image旧命令）
		docker images -q			显示所有镜像的id
		docker tag id 镜像名字:镜像版本	修改镜像名字和版本
		docker rmi 83 --force(强制)		删除镜像（i镜像  83为镜像的id的前两位也可以是完整的名字[docker.io/ubuntu:latest 要加上版本不写默认为最新版本]）
		docker rmi 94 bb			删除多个·
		docker ps 			查看运行的容器
		docker ps	 -a 			查看所有容器
		docker ps	 -a -q 			查看所有容器的id
		docker inspect d5			查看容器详细信息（可查看ip）
		docker inspect --format='{{.NetworkSettings.IPAddress}}' d5       （拿到你想要的一行信息，一个括号一个括号写下来）
		docker stop 94			停止运行的容器
		docker kill 94			强制停止
		docker start 94			启动容器
		docker restart 94			重启
		docker run -it centos /bin/bash	-i捕获标准输入输出-t分配一个终端或控制台（-h ip 连接远程的容器）(-d放到后台)
		docker create -it centos /bin/bash	创建不启动
		docker attach d5 （docker exec -it 8cc /bin/bash）连接到运行中的容器的终端
		docker exec 8cc touch /tmp/cccc	不连进去但是在容器中执行命令
		ctrl+p+q				退出终端到宿主机但不关闭容器
		docker top 8cc			显示容器内的进程
		docker cp /root/aa 0c:/root		类似scp（拷贝目录不用加-r）
		docker run -it -v /aa:/bb centos /bin/bash   (必须是新创建的容器，容器卷，两边互通同会自动创建所写目录，这样就不用cp了)
		docker run -it --volumes-from 其他容器id 镜像id /bin/bash 		创建时共享其他容器的卷
		docker diff 94			看到容器内那些文件有改动（查看到的信息中C时内容的改变，A是创建和删除）
	创建自己的镜像
		docker export -o 所要压缩成的tar文件 容器id	将容器打包成镜像
		docker import  压缩文件tar  新起一个名称:版本	导入镜像
		docker save -o 压缩包名字  镜像id		将镜像打包
		docker load < 压缩包名字			导入镜像
		通过Dockerfile文件创建镜像  常用
			mkdir ww
			cd ww
			vim Dockerfile 	必须是这个命令
				FROM daocloud.io/library/centos:5      在什么镜像的基础之上，本地没有则会下载
				MAINTAINER wing wing@ww.com	作者信息
				RUN touch /a.txt			在镜像上做什么操作可写多条
			docker build -t 镜像名称:版本 Dockerfile文件的路径     形成镜像
			docker image list				查看
	构建私有仓库
		docker pull daocloud.io/library/registry		下载构建仓库所需的镜像
		docker run -d -p 5000:5000 --restart=always -v /data/docker/registry/:/var/lib/registry/ --name registry registry
		vim /usr/lib/systemd/system/docker.service
			ExecStart=/usr/bin/dockerd-current \
			          --exec-opt native.cgroupdriver=systemd \   		--userland-proxy-path=/usr/libexec/docker/docker-proxy-current \
			          --insecure-registry=192.168.131.130:5000 \		docker registry交互默认使用的是https，而默认是http
		或者
			vim /etc/sysconfig/docker				不用systemctl daemon-reload，只需重启docker
				OPTIONS='--insecure-registry 192.168.131.130:5000'
		systemctl daemon-reload
		systemctl restart docker
		docker pull busybox
		docker tag busybox 192.168.95.137:5000/busybox	打上私有库的标记
		docker push 192.168.95.137:5000/busybox		上传镜像到私有库
		docker pull 192.168.95.137:5000/busybox   （别的主机拉去也需要修改配置文件）
		curl http://192.168.131.130:5000/v2/_catalog		查看库中有什么镜像


k8s(谷歌的一种容器编排引擎，用于管理docker容器的软件)
	概念
		Pod:直译是豆荚，可以把容器想象成豆荚里的豆子（一个Pod里可以有一个或多个容器形成一个Pod），k8s管理的最小单位。
		        pod运行在node上(节点也就是一台宿主机),node上可以有多个Pod
		       pod创建完后k8s会为其分配一个ip让别人访问，这个ip加上端口就是Endpoint端点(别人通过访问这个端点来访问pod)
		service：同一个pod可能有多个副本，用户不能确定访问哪个pod，所以service实现对他们的访问类似于负载均衡器（只能在k8s内访问，在外访问需要平台支持，例如谷歌的GCE、亚马逊aws、阿里ecs等公有云平台）
		Cluster IP: service的ip（可以用但不能被ping），同过访问这个ip +端口来访问service 
		Node IP :节点IP	  
		RC(Replication Controller)副本控制器，创建pod副本就是由其创建（副本是同时产生的，而不是事先存在一个pod再对其创建副本）
			包括创建删除等（若集群中副本数大于指定数会自动删除，小于时则会自动创建增加）
		deployment同RC，现在不指定时默认使用的就是deplpyment 
		label标签:一个资源可以打上任何数量的label,相当于给他打上一个标签，随后可通过标签进行筛选  

		node、pod、replication controller和service等都可以看作是一种资源对象，几乎所有的资源对象都可以通过kubernets提供的kubectl工具执行
		增删改查等操作并将其保存在etcd数据库中持久化存储  
		架构分为两个节点
				master  概念负责创建什么样的放到哪里在哪里创建api server、scheduler、RC、etcd
				node    具体创建	kubelet docker引擎 kube proxy（也就是service的代理）
				具体过程：用户通过 kubectl(或者web UI）提交要运行的docker容器（pod）
				  	api server(应用程序接口服务器k8s系统入口)把请求存储到etcd数据库里
					etcd返回数据给api server拿到要创建的RC
					scheduler（调度器）扫描，分配机器（在哪里创建pod）
					找到具体机器上的kubelet创建工具创建（其还要去找docker创建）
	集群
		master
			yum -y install etcd
			vim /etc/etcd/etcd.conf
				ETCD_LISTEN_CLIENT_URLS="http://0.0.0.0:2379,http://0.0.0.0:4001"   监控本地的2个端口
				ETCD_NAME="master"	etcd的名字
				ETCD_ADVERTISE_CLIENT_URLS="http://etcdip:2379,http://etcdip:4001"	别人通过什么ip访问我
			systemctl start etcd.service
			systemctl enable etcd
			etcdctl set testdir/testkey0 0     (判断etcd是否可用)
			etcdctl get testdir/testkey0 0     （key-value的方式）
			etcdctl -C http://192.168.131.130:4001 cluster-health    判断远程接口是否可用

			yum -y install docker
			vim /etc/sysconfig/docker
				OPTIONS='--insecure-registry 192.168.131.130:5000'            配置私有库的访问
			systemctl start docker
			systemctl enable docker
		
			yum -y install kubernetes
			vim /etc/kubernetes/apiserver          		api server
				KUBE_API_ADDRESS="--insecure-bind-address=0.0.0.0"     监控本地所有的网卡
				KUBE_API_PORT="--port=8080"			监控的端口
				KUBE_ETCD_SERVERS="--etcd-servers=http://192.168.131.130:2379"       etcd数据库的地址
				KUBE_ADMISSION_CONTROL="--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ResourceQuota"      k8s支持的控制器策略
			vim /etc/kubernetes/config	
				KUBE_MASTER="--master=http://192.168.131.130:8080"         k8s如何联系api server  配上apiserver的地址
			systemctl start kube-apiserver.service
			systemctl start kube-controller-manager.service
			systemctl start kube-scheduler.service
			systemctl enable kube-apiserver.service
			systemctl enable kube-controller-manager.service
			systemctl enable kube-scheduler.service
			
		node
			yum -y install docker
			systemctl start docker
			systemctl enable docker
			yum -y install kubernetes
			vim /etc/kubernetes/config
				KUBE_MASTER="--master=http://192.168.131.130:8080" 
			vim /etc/kubernetes/kubelet
				KUBELET_ADDRESS="--address=0.0.0.0"
				KUBELET_HOSTNAME="--hostname-override=192.168.131.131"       node的ip
				KUBELET_API_SERVER="--api-servers=http://192.168.131.130:8080"
			systemctl start kubelet.service kube-proxy.service	
			systemctl enable kubelet.service kube-proxy.service
		测试
			kubectl -s http://192.168.131.130:8080 get node       master上查看节点是否健康
			kubectl get node
		master和node上配置flannel          用于建立统一的子网进行管理（实现不同物理机之间运行的docker容器的通讯）
			yum -y install flannel
			vim /etc/sysconfig/flanneld
				FLANNEL_ETCD_ENDPOINTS="http://192.168.131.130:2379"      etcd的ip地址   
			master上  etcdctl mk /atomic.io/network/config '{ "Network":"172.17.0.0/16"}'  建立一个大子网     (建立的网络保存在etcd数据库中)
				etcdctl update /atomic.io/network/config '{ "Network":"172.17.0.0/16"}'   (配置时不用做，重启网络不好时做，或者删除原来网络重新建立一个)
				配置完flanneld后启动后需要依次重启docker 和kubernetes服务
				systemctl start flanneld.service
				systemctl enable flanneld.service
				systemctl restart docker
				systemctl restart kube-apiserver.service
				systemctl restart kube-controller-manager.service
				systemctl restart kube-scheduler.service
				systemctl restart  flanneld.service kube-apiserver.service kube-controller-manager.service kube-scheduler.service
			node上
				systemctl start flanneld.service
				systemctl enable flanneld.service
				systemctl restart docker
				systemctl restart flanneld.service kubelet.service kube-proxy.service    (ping不通时该node节点开关防火墙)
			每台机器上可通过cat /run/flannel/subnet.env   查看自己的小子网
		在master上创建私有库（应该单独部署在一台机器上）
			docker pull daocloud.io/registry
			docker run -d -p 5000:5000 --name=registry --restart=always --privileged=true --log-driver=none -v /home/data/registrydata:/tmp/registry daocloud.io/registry      -restart=always一直重启 --privileged=true高级权限 --log-driver=none打开启印容器级别日志.
			vim /usr/lib/systemd/system/docker.service				（k8s所有机器若要使用私有仓库都要更改此配置文件)
				ExecStart=/usr/bin/dockerd-current \
			          		--exec-opt native.cgroupdriver=systemd \   		--userland-proxy-path=/usr/libexec/docker/docker-proxy-current \
			         		 --insecure-registry=192.168.131.130:5000 \		docker registry交互默认使用的是https，而默认是http
			systemctl daemon-reload
			systemctl restart docker
			docker pull busybox
			docker tag busybox 192.168.131.130:5000/busybox	打上私有库的标记
			docker push 192.168.131.130:5000/busybox		上传镜像到私有库
			docker pull 192.168.95.137:5000/busybox   （别的主机拉去也需要修改配置文件）
			curl http://192.168.131.130:5000/v2/_catalog		查看库中有什么镜像
		集群中部署项目前提(已经部署了私库）
			master
				docker pull docker.io/tianyebj/pod-infrastructure
				docker tag docker.io/tianyebj/pod-infrastructure 192.168.131.130:5000/pod-infrastructure
				docker push 192.168.131.130:5000/pod-infrastructure
				vim /etc/kubernetes/kubelet
					KUBELET_POD_INFRA_CONTAINER="--pod-infra-container-image=192.168.131.130:5000/pod-infrastructure"
				systemctl restart  kubelet.service
			node
				vim /etc/kubernetes/kubelet
					KUBELET_POD_INFRA_CONTAINER="--pod-infra-container-image=192.168.131.130:5000/pod-infrastructure"
				systemctl restart  kubelet.service
		集群内通讯的过程
			容器实例->docker0桥接设备（在node上）->flannel0隧道->node的ens33->master的flannel0   
			由于flannel的存在从而使得不同物理机之间的docker容器也能够互相通讯
		k8s中基本命令
			master中
				kubectl get nodes    查看所有节点
				kubectl delete node ip    删除节点信息（无效节点信息仍然保存时执行）
				kubectl describe node 192.168.131.131            显示节点的详细信息
				kubectl get service
				kubectl run ww-nginx --image=daocloud.io/nginx --replicas=2 --port=80        命令的方式创建资源创建两个副本（要等一下才能查看，因为在下载镜像）
				kubectl get deployment           查看部署过的东西
				kubectl get pods 		查看pods的信息
				kubectl get pods -o wide	全部pod的详细信息部署在哪里以及pod的ip（ip可ping,如果ping不通则在运行容器的node上开关防火墙，全部节点重启flanneld)(例如在容器内启动nginx就可以通过这个ip访问）
				kubectl get pod  pod名字 -o json    查看
				kubectl describe pod名字 查看某个pod的详细信息  
				kubectl create -f nginx.yaml
				kubectl delete -f nginx.yaml
				kubectl get pod swy-nginx -o wide
				kubectl delete pod pod名字   删除pod（rc存在的话则不会删除，会自动创建回去） 
				kubectl get rc rc名字       查看rc
				kubectl delete rc rc名字           pod会随rc一起删除
				kubectl get rc my-nginx-rc -o wide 
				kubectl get service
				kubectl get deployment 新一代的RC
				kubectl get deployment my-nginx --export -o yaml >nginx.yaml   本地快速获取yaml文件进行修改
		YAML创建资源
			语法规则
				1、大小写敏感
				2、使用缩进表示层级关系
				3、缩进时不允许使用tab键，只允许使用空格
				4、缩进的空格数不重要，只要相同层级的元素左侧对齐即可
				5、"表示注释，从这个字符一直到行尾，都会被解析器忽略
			两种结构
				1、Lists 列表   [1,2,3]        一个元素前要加一个-
				2、Maps 字典 [a:1,b:2,c:3]          {a:{d:11,e:12},b:[1,2,{f:13,k:12},5]}    字典嵌套字典和列表，列表嵌套字典和列表
					{a:{d:11,e:12},b:[1,2,{f:13,k:12},5]}
					a:
					 d: 11
					 e: 12
					b:
					 - 1
					 - 2
					 - f: 13
					   k: 12
					 - 5
			创建pod
				apiVersion: v1                版本
				kind: Pod		  创建的是什么资源	
				metadata:                   元属性
				 name: swy-nginx       pod名称
				 labels:                        标签   
				  web: nginx
				  nginx: nginx1
				spec:                            指定资源的内容
				 containers:               
				  - name: swy-nginx-containers                 有多个容器则写多个 - name：下来
				     image: daocloud.io/library/nginx
 				     ports:
				      - containerPort: 80

				kubectl create -f swy-nginx.yaml
			创建rc
				apiVersion: v1      （extensions/v1beta1）deployment新一代的RC
				kind: ReplicationController        (Deployment)
				metadata:
				 name: my-nginx-rc
				spec:
				 replicas: 2
				 template:
				  metadata:
				   labels:
				    name: nginx-rc
				    app: nginx
				  spec:
				   containers:
				    - name: swy-nginx-containers
				      image: daocloud.io/library/nginx
				      ports:
				       - containerPort: 80
				      volumeMounts:
				       - name: testpath          名字要和volumes里面定义的名字要一直
				         mountPath: /testpath        可以事先不存在
				   volumes:
				    - name: testpath
                                                                       hostPath:
                                                                        path: /testpath                    可以事先不存在
			创建service
				apiVersion: v1
				kind: Service
				metadata:
				 name: my-nginx-service-nodeport
				spec:
				 ports:
				  - port: 8001                      集群内相互访问的端口      （给集群内访问）
				    targetPort: 80                 外部访问容器内的端口（容器的端口（最终的流量端口）从port和nodePort上来的流量，经过kube-proxy流入到后端pod的targetPort上，最后进入容器。）
				    nodePort: 30062             固定暴露的端口（访问service）	（给集群外访问）
				    protocol: TCP
				 type: NodePort            暴露端口给外网（通过容器所在node的ip加上端口即可访问，端口可通过get service查看，然后再用keepalived+lvs做）
				 selector:                   选择器和哪个rc关联（selector下写的内容，与关联的rc的pod模板的labels内容一致即可关联）
				  name: nginx

				kubectl create -f my-nginx-servce.yaml

			容器卷的使用
			      image: 192.168.131.130:5000/redis-master
			      ports:
			       - containerPort: 80
			      volumeMounts:
			       - name: testpath
			         mountPath: /testpath
			   volumes:
			    - name: testpath
			      hostPath:
			       path: /testpath